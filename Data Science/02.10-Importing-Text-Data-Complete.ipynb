{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.loadtxt() vs np.genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_1 = np.loadtxt(\"Lending-Company-Numeric-Data.csv\", delimiter = ',')\n",
    "lending_co_data_numeric_1\n",
    "\n",
    "# We can use Notepad++ to determine delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_2 = np.genfromtxt(\"Lending-Company-Numeric-Data.csv\", delimiter = ',')\n",
    "lending_co_data_numeric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(lending_co_data_numeric_1, lending_co_data_numeric_2)\n",
    "\n",
    "## np.array_equal() compares two (or more) arrays and tells us if whether they're identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '' to float64 at row 11, column 4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lending_co_data_numeric_NAN \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLending-Company-Numeric-Data-NAN.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m lending_co_data_numeric_NAN\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# np.loadtxt() fails to import incomplete datasets by default\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1397\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1395\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1036\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1036\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string '' to float64 at row 11, column 4."
     ]
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\n",
    "    \"Lending-Company-Numeric-Data-NAN.csv\", delimiter=';')\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# np.loadtxt() fails to import incomplete datasets by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2000', '40', '365', '3121', '4241', '13621'],\n",
       "       ['2000', '40', '365', '3061', '4171', '15041'],\n",
       "       ['1000', '40', '365', '2160', '3280', '15340'],\n",
       "       ...,\n",
       "       ['', '40', '365', '4201', '5001', '16600'],\n",
       "       ['1000', '40', '365', '2080', '3320', '15600'],\n",
       "       ['2000', '40', '365', '4601', '4601', '16600']], dtype='<U5')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.loadtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                         delimiter = ';',\n",
    "                                         dtype = str)\n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# If we import all the values as text, then we don't get a type inconcsistency, so we can use np.loadtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200040'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN[0,0] + lending_co_data_numeric_NAN[0,1]\n",
    "\n",
    "# Adding '2000' and '40' results in a concatenated '200040' rather than 2040."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Cleaning While Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", delimiter = ';') \n",
    "lending_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            skip_header = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# skip_header omits lines from the top of the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            skip_footer = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# skip_footer omits lines from the bottom of the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13621.,  2000.,    40.],\n",
       "       [15041.,  2000.,    40.],\n",
       "       [15340.,  1000.,    40.],\n",
       "       ...,\n",
       "       [16600.,    nan,    40.],\n",
       "       [15600.,  1000.,    40.],\n",
       "       [16600.,  2000.,    40.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            usecols = (5,0,1)) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# use_cols tells the function to only take the following columns based on their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_co_data_numeric_NAN = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                            delimiter = ';',\n",
    "                                            usecols = (5,0,1), \n",
    "                                            skip_header = 2, \n",
    "                                            skip_footer = 2) \n",
    "lending_co_data_numeric_NAN\n",
    "\n",
    "# We can define all these arguments (and many more) together to only import what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15340. 15321. 13720. ... 16600. 16600. 16600.]\n",
      "[1000. 2000. 2000. ... 2000. 2000.   nan]\n",
      "[40. 40. 50. ... 40. 40. 40.]\n"
     ]
    }
   ],
   "source": [
    "lending_co_data_5, lending_co_data_0, lending_co_data_1 = np.genfromtxt(\"Lending-Company-Numeric-Data-NAN.csv\", \n",
    "                                                                        delimiter = ';',\n",
    "                                                                        usecols = (5,0,1), \n",
    "                                                                        skip_header = 2, \n",
    "                                                                        skip_footer = 2, \n",
    "                                                                        unpack = True)\n",
    "print(lending_co_data_5)\n",
    "print(lending_co_data_0)\n",
    "print(lending_co_data_1)\n",
    "\n",
    "# Unpacking allows us to split the output array into smaller 1-D arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### String vs Object vs Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LoanID' 'StringID' 'Product' ... 'Location' 'Region' 'TotalPrice']\n",
      " ['1' 'id_1' 'Product B' ... 'Location 2' 'Region 2' '16600.0']\n",
      " ['2' 'id_2' 'Product B' ... 'Location 3' '' '16600.0']\n",
      " ...\n",
      " ['1041' 'id_1041' 'Product B' ... 'Location 23' 'Region 4' '16600.0']\n",
      " ['1042' 'id_1042' 'Product C' ... 'Location 52' 'Region 6' '15600.0']\n",
      " ['1043' 'id_1043' 'Product B' ... 'Location 142' 'Region 6' '16600.0']]\n"
     ]
    }
   ],
   "source": [
    "lending_co_lt = np.genfromtxt(\"lending-co-LT.csv\", \n",
    "                              delimiter = ',',\n",
    "                            #   dtype = np.int32\n",
    "                            #   dtype = np.float16\n",
    "                              dtype = str\n",
    "                              #dtype = np.object\n",
    "                              #dtype = (np.int32, np.str, np.str, np.str, np.str, np.str, np.int32)\n",
    "                             )\n",
    "print(lending_co_lt)\n",
    "\n",
    "# The same dataset is imported differently based on the datatype we define. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LoanIDStringID'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lending_co_lt[0,0] + lending_co_lt[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
