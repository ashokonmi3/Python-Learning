{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Handle Missing Data:\n",
    "\n",
    "In machine learning, missing data is a common problem. If your data has missing values, it can affect the accuracy of your model. Therefore, it is important to handle missing data properly.\n",
    "\n",
    "Here’s a simple guide to help you understand how to handle missing data, along with some Python code examples.\n",
    "\n",
    "## What is Missing Data?\n",
    "\n",
    "Missing data occurs when some values in your dataset are not available. These missing values could be caused by errors in data collection, user input mistakes, or other issues.\n",
    "\n",
    "**Example**: In a dataset of houses, the column for \"Number of Rooms\" might be missing for some houses.\n",
    "\n",
    "---\n",
    "\n",
    "## Methods to Handle Missing Data\n",
    "\n",
    "There are several ways to handle missing data:\n",
    "\n",
    "### 1. Removing Rows with Missing Data\n",
    "If the missing data is very small (only a few rows), you can simply **remove** the rows that contain missing values. This is the simplest approach but should only be used if the number of missing values is not significant.\n",
    "\n",
    "**Python Code to Remove Missing Data:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data with Missing Values:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3     NaN   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5     NaN   Suburb       NaN\n",
      "\n",
      "\n",
      "Cleaned Data (after removing rows with missing values):\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "4  2200.0     City  400000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = {\n",
    "    # 'None' represents missing values\n",
    "    'Size': [1200, 1500, 800, None, 2200, None],\n",
    "    'Location': ['City', 'Suburb', 'City', 'Suburb', 'City', 'Suburb'],\n",
    "    # 'None' represents missing values\n",
    "    'Price': [250000, 300000, 200000, 350000, 400000, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original dataset with missing values\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "print(\"\\n\")  # Adding a newline for better readability\n",
    "\n",
    "# Remove rows with missing data\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(\"Cleaned Data (after removing rows with missing values):\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Missing Values with Mean, Median, or Mode\n",
    "\n",
    "Sometimes, it's better to **fill in the missing values** with a statistic like the **mean**, **median**, or **mode**. This approach is especially useful when you have a lot of missing values and removing them would result in losing too much data.\n",
    "\n",
    "### **What Are These Statistics?**\n",
    "\n",
    "- **Mean**: The **average** of all values in a column. It is calculated by adding all the values and dividing by the total number of values.\n",
    "  \n",
    "- **Median**: The **middle value** in a sorted list of values. If the data has an odd number of values, it’s the exact middle value; if even, it’s the average of the two middle values.\n",
    "\n",
    "- **Mode**: The **most frequent value** in the dataset. If there are multiple values that appear most frequently, the dataset can have more than one mode.\n",
    "\n",
    "### **When to Use Each?**\n",
    "\n",
    "- **Mean**: Use the mean when the data is approximately normally distributed (i.e., most values are clustered around the average).\n",
    "- **Median**: Use the median when your data has outliers or is skewed, as it is less affected by extreme values.\n",
    "- **Mode**: Use the mode for categorical data, where you are looking for the most frequent category.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Code: Filling Missing Values**\n",
    "\n",
    "Here’s how you can fill missing values using the mean, median, or mode in Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data After Filling Missing Values:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3  1425.0   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5  1425.0   Suburb  300000.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = {\n",
    "    # 'None' represents missing values\n",
    "    'Size': [1200, 1500, 800, None, 2200, None],\n",
    "    'Location': ['City', 'Suburb', 'City', 'Suburb', 'City', 'Suburb'],\n",
    "    # 'None' represents missing values\n",
    "    'Price': [250000, 300000, 200000, 350000, 400000, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing values in 'Size' column with the mean\n",
    "df['Size'] = df['Size'].fillna(df['Size'].mean())\n",
    "\n",
    "# Fill missing values in 'Price' column with the median\n",
    "df['Price'] = df['Price'].fillna(df['Price'].median())\n",
    "\n",
    "# Fill missing values in 'Location' column with the mode\n",
    "df['Location'] = df['Location'].fillna(df['Location'].mode()[0])\n",
    "\n",
    "# Show the data after filling missing values\n",
    "print(\"Data After Filling Missing Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data with Missing Values:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3     NaN   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5     NaN   Suburb       NaN\n",
      "\n",
      "\n",
      "After filling 'Size' with Mean:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3  1425.0   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5  1425.0   Suburb       NaN\n",
      "\n",
      "\n",
      "After filling 'Price' with Median:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3  1425.0   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5  1425.0   Suburb  300000.0\n",
      "\n",
      "\n",
      "After filling 'Location' with Mode:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3  1425.0   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5  1425.0   Suburb  300000.0\n",
      "\n",
      "\n",
      "Final Data After Filling All Missing Values:\n",
      "     Size Location     Price\n",
      "0  1200.0     City  250000.0\n",
      "1  1500.0   Suburb  300000.0\n",
      "2   800.0     City  200000.0\n",
      "3  1425.0   Suburb  350000.0\n",
      "4  2200.0     City  400000.0\n",
      "5  1425.0   Suburb  300000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = {\n",
    "    # 'None' represents missing values in 'Size'\n",
    "    'Size': [1200, 1500, 800, None, 2200, None],\n",
    "    # Categorical data in 'Location'\n",
    "    'Location': ['City', 'Suburb', 'City', 'Suburb', 'City', 'Suburb'],\n",
    "    # 'None' represents missing values in 'Price'\n",
    "    'Price': [250000, 300000, 200000, 350000, 400000, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original dataset with missing values\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "print(\"\\n\")  # Adding a newline for better readability\n",
    "\n",
    "# Fill missing values in 'Size' column with the mean value of the 'Size' column\n",
    "df['Size'] = df['Size'].fillna(df['Size'].mean())\n",
    "print(\"After filling 'Size' with Mean:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill missing values in 'Price' column with the median value of the 'Price' column\n",
    "df['Price'] = df['Price'].fillna(df['Price'].median())\n",
    "print(\"After filling 'Price' with Median:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill missing values in 'Location' column with the mode (most frequent) value of the 'Location' column\n",
    "df['Location'] = df['Location'].fillna(df['Location'].mode()[0])\n",
    "print(\"After filling 'Location' with Mode:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Final data after all missing values have been filled\n",
    "print(\"Final Data After Filling All Missing Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Forward or Backward Fill\n",
    "\n",
    "If the missing values are in a **time series** (data collected over time), you can use **forward fill** or **backward fill** to handle the missing values. These methods are useful when you want to preserve the sequence of the data.\n",
    "\n",
    "### **What is Forward Fill?**\n",
    "- **Forward fill** means filling the missing value with the **previous** available value. This approach works well when the values in the data are expected to stay the same or change gradually over time.\n",
    "  \n",
    "### **What is Backward Fill?**\n",
    "- **Backward fill** means filling the missing value with the **next** available value. This method is useful when the data points following the missing value are likely to be more relevant or reflect the missing value more accurately.\n",
    "\n",
    "### **When to Use Forward or Backward Fill?**\n",
    "- **Forward Fill**: Use forward fill when the missing values are likely to be similar to the previous data point. This is often the case in time-series data, where values don't change drastically from one time point to the next.\n",
    "- **Backward Fill**: Use backward fill when the missing data can be better predicted by the values that follow it.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Code: Forward and Backward Fill**\n",
    "\n",
    "Here’s how you can use **forward fill** and **backward fill** to fill missing values in time-series data using Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset with missing values (simulating time-series data)\n",
    "data = {\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'Temperature': [30, None, 28, None, 32]  # 'None' represents missing values\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original dataset with missing values\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Forward fill: Fill missing values with the previous available value\n",
    "df_forward_filled = df.fillna(method='ffill')\n",
    "print(\"Data After Forward Fill:\")\n",
    "print(df_forward_filled)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Backward fill: Fill missing values with the next available value\n",
    "df_backward_filled = df.fillna(method='bfill')\n",
    "print(\"Data After Backward Fill:\")\n",
    "print(df_backward_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Using Algorithms\n",
    "\n",
    "For more complex datasets, you can use **machine learning algorithms** to predict and **impute missing values** based on other features in the data. This approach is more advanced and can be very useful when the missing data cannot be easily filled using simple methods like mean, median, or mode.\n",
    "\n",
    "### **What is Imputation Using Algorithms?**\n",
    "\n",
    "- **Imputation** is the process of replacing missing values with estimated ones.\n",
    "- When **simple imputation methods** (like filling with mean, median, or mode) are not sufficient or appropriate, **machine learning algorithms** can be used to **predict** the missing values.\n",
    "- This process involves training a model to understand the relationships between different features (columns) in the data and then using that model to predict the missing values.\n",
    "\n",
    "### **How Does It Work?**\n",
    "\n",
    "1. **Train a Model**: You first train a machine learning model (e.g., decision tree, regression model, k-nearest neighbors) on the data with missing values, using the other available features to predict the missing ones.\n",
    "2. **Predict Missing Values**: The trained model is then used to **predict** the missing values based on the patterns it learned from the complete data.\n",
    "3. **Fill Missing Data**: Once the missing values are predicted, they are filled into the dataset.\n",
    "\n",
    "### **When to Use Imputation Algorithms?**\n",
    "\n",
    "- **When the missing data is not missing at random**: Sometimes, the missing values themselves contain valuable information. For example, if a survey response is missing, it might be important to know that the response was never provided, rather than just filling it in with an arbitrary value.\n",
    "- **When simple methods fail to provide reasonable results**: If the dataset is large and has complex relationships between features, machine learning-based imputation could give better results.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Imputation Using K-Nearest Neighbors (KNN)**\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple and effective algorithm for imputation. It works by finding the closest data points (neighbors) to the missing value and using their values to impute the missing data.\n",
    "\n",
    "Here’s how you can perform imputation using KNN in Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, 35, None, 40, None],\n",
    "    'Salary': [50000, 60000, 70000, 80000, 90000, None],\n",
    "    'Experience': [2, 5, 8, 10, 12, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original dataset with missing values\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Initialize KNNImputer with 2 neighbors\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Fit the imputer on the dataset and transform (fill missing values)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "# Display the dataset after imputation\n",
    "print(\"Data After KNN Imputation:\")\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Outliers in Data\n",
    "\n",
    "## What is an Outlier?\n",
    "\n",
    "An **outlier** is a data point that is significantly different from the rest of the data. It’s like a student in a class who is much taller or shorter than everyone else, or a person whose age is much higher or lower than the average group. These unusual data points can have a big impact on how we analyze and interpret data.\n",
    "\n",
    "### Example of an Outlier:\n",
    "Imagine you are collecting the heights of students in a class:\n",
    "- Most students have heights around **150 cm to 170 cm**.\n",
    "- However, one student is **220 cm** tall. \n",
    "\n",
    "This **220 cm** height is much different from the others and is considered an **outlier**. It might be due to a mistake, or it could simply be a unique case.\n",
    "\n",
    "## Why Are Outliers Important?\n",
    "\n",
    "Outliers are important to identify because:\n",
    "1. **They can skew results**: If we are calculating averages (like the average height of the class), the outlier (the very tall student) can push the average higher than it should be.\n",
    "2. **They can affect machine learning models**: In machine learning, outliers can make the model focus too much on unusual data points, which can reduce its ability to make accurate predictions.\n",
    "\n",
    "## How to Handle Outliers\n",
    "\n",
    "When you encounter outliers, you have a few options for what to do with them:\n",
    "\n",
    "1. **Remove the Outlier**:\n",
    "   - If the outlier is a mistake or irrelevant (e.g., a data entry error), you can **remove** it from the data.\n",
    "   \n",
    "2. **Cap the Outlier**:\n",
    "   - Instead of removing it, you might **limit** the outlier's value to a certain range. For example, if the class height range is 150 cm to 170 cm, you might set the maximum height to **170 cm** and cap the outlier at that value.\n",
    "\n",
    "3. **Transform the Data**:\n",
    "   - Sometimes, we can change the way we look at the data to make outliers less impactful. For example, we can use a **log transformation** to reduce the effect of extreme values.\n",
    "\n",
    "## How to Identify Outliers?\n",
    "\n",
    "There are a few common ways to find outliers:\n",
    "\n",
    "1. **Visual Inspection**:\n",
    "   - **Graphs** like bar charts or scatter plots can help you visually spot outliers. A point that stands far away from the rest of the data can be an outlier.\n",
    "   \n",
    "2. **Statistical Methods**:\n",
    "   - **Z-Score**: This method calculates how far a data point is from the average. If the value is too far away (for example, more than 3 standard deviations), it might be an outlier.\n",
    "   - **IQR (Interquartile Range)**: This method involves dividing the data into four parts. If a value is significantly smaller or larger than most of the data, it could be an outlier.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Outliers are data points** that are very different from most of the other data.\n",
    "- **Outliers can affect** the accuracy of data analysis or machine learning models.\n",
    "- **You can handle outliers** by removing them, capping them, or using transformations.\n",
    "- **Identifying outliers** can be done through visual inspection or statistical methods like Z-scores and IQR.\n",
    "\n",
    "By understanding and handling outliers correctly, we ensure that our analysis and models are more accurate and reliable!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data: Heights of students in a class\n",
    "heights = [150, 160, 155, 165, 170, 175, 180, 220, 160, 158]\n",
    "\n",
    "# Convert to a pandas Series (a column of data)\n",
    "data = pd.Series(heights)\n",
    "\n",
    "# Step 1: Calculate the Interquartile Range (IQR)\n",
    "Q1 = data.quantile(0.25)  # First Quartile (25th percentile)\n",
    "Q3 = data.quantile(0.75)  # Third Quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # IQR is the difference between Q3 and Q1\n",
    "\n",
    "# Step 2: Define the lower and upper bounds to detect outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "# Tukey's rule states that:\n",
    "# Any value below Q1 - 1.5 * IQR is considered a lower outlier.\n",
    "# Any value above Q3 + 1.5 * IQR is considered an upper outlier.\n",
    "\n",
    "# Step 3: Identify outliers\n",
    "outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "\n",
    "# Step 4: Remove outliers (optional)\n",
    "data_no_outliers = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "\n",
    "# Step 5: Cap outliers (optional)\n",
    "data_capped = data.copy()\n",
    "data_capped[data_capped < lower_bound] = lower_bound\n",
    "data_capped[data_capped > upper_bound] = upper_bound\n",
    "\n",
    "# Print results\n",
    "print(\"Original Data:\", heights)\n",
    "print(\"Outliers:\", outliers.tolist())\n",
    "print(\"Data without outliers:\", data_no_outliers.tolist())\n",
    "print(\"Data with capped outliers:\", data_capped.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Inconsistent Data: What Does It Mean?\n",
    "\n",
    "When working with data, **inconsistent data** refers to information that is incorrect, unorganized, or formatted differently than expected. This inconsistency can occur in many ways, like typos, inconsistent naming, or wrong formatting. Fixing this helps ensure that the data is accurate and easy to work with, especially when we're trying to make decisions or predictions.\n",
    "\n",
    "## Why Is It Important to Fix Inconsistent Data?\n",
    "\n",
    "Imagine you're trying to create a list of all the students in a class, but some students’ names are written with typos, others are capitalized differently, and some have extra spaces. When you try to analyze this list, you might end up counting the same student twice or missing someone. This leads to incorrect results. Fixing inconsistent data makes sure that:\n",
    "\n",
    "- We treat similar information in the same way.\n",
    "- We avoid errors in analysis or decision-making.\n",
    "- The data is uniform and can be easily processed.\n",
    "\n",
    "## Types of Inconsistent Data and How to Fix Them\n",
    "\n",
    "### Typos and Spelling Errors:\n",
    "Sometimes, data entries might have small mistakes like misspelled words. For example:\n",
    "- \"John\" might be written as \"Jonh\".\n",
    "- \"London\" might be spelled as \"Londan\".\n",
    "\n",
    "**How to Fix**: You can go through the data and correct the spelling, or use tools that automatically detect and fix typos.\n",
    "\n",
    "### Inconsistent Naming:\n",
    "The same thing might be called by different names, like:\n",
    "- \"NY\", \"New York\", and \"New York City\" all referring to the same place.\n",
    "- \"USA\", \"United States\", and \"America\" being used interchangeably.\n",
    "\n",
    "**How to Fix**: Decide on a **standard name** for each category and change all the entries to match that. For example, you could choose to use **\"New York\"** consistently instead of the variations.\n",
    "\n",
    "### Inconsistent Capitalization:\n",
    "Inconsistent use of capital letters can be confusing. For example:\n",
    "- \"john\" vs \"John\".\n",
    "- \"USA\" vs \"usa\".\n",
    "\n",
    "**How to Fix**: You can standardize the capitalization by making all names or place names start with a capital letter (e.g., \"John\" instead of \"john\").\n",
    "\n",
    "### Extra Spaces:\n",
    "Sometimes there might be extra spaces before or after the data, like:\n",
    "- \" John\" (with a space before the name) or \"USA \" (with a space after the name).\n",
    "\n",
    "**How to Fix**: Simply **remove** the extra spaces so that the data is neat and consistent.\n",
    "\n",
    "### Wrong Formatting:\n",
    "Sometimes, the data may have the wrong format, for example:\n",
    "- A **phone number** could be written as **\"123-456-7890\"** in one place and **\"123 456 7890\"** in another.\n",
    "- **Dates** might be written as **\"MM/DD/YYYY\"** in one part of the dataset and **\"YYYY/MM/DD\"** in another.\n",
    "\n",
    "**How to Fix**: Decide on the correct format (e.g., for phone numbers, always use **\"123-456-7890\"**) and convert all the data to that format.\n",
    "\n",
    "## Example of Fixing Inconsistent Data\n",
    "\n",
    "Let’s say you're working with a list of customers, and there are some inconsistencies:\n",
    "\n",
    "| Customer Name | Location         | Phone Number     |\n",
    "|---------------|------------------|------------------|\n",
    "| John          | New York         | 123 456 7890     |\n",
    "| Jonh          | USA              | 123-456-7890     |\n",
    "| Jane          | new york city    | 987 654 3210     |\n",
    "| jane          | NY               | 987-654-3210     |\n",
    "\n",
    "- **Typos**: \"Jonh\" should be \"John\".\n",
    "- **Inconsistent Naming**: \"New York City\", \"NY\", and \"USA\" should all be standardized to \"New York\".\n",
    "- **Inconsistent Formatting**: The phone numbers should be consistent, either \"123-456-7890\" or \"123 456 7890\", but not both.\n",
    "\n",
    "After fixing the inconsistencies, the data might look like this:\n",
    "\n",
    "| Customer Name | Location  | Phone Number    |\n",
    "|---------------|-----------|-----------------|\n",
    "| John          | New York  | 123-456-7890    |\n",
    "| John          | New York  | 123-456-7890    |\n",
    "| Jane          | New York  | 987-654-3210    |\n",
    "| Jane          | New York  | 987-654-3210    |\n",
    "\n",
    "Now, the data is consistent, and it's easier to analyze and use for decisions.\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "- **Inconsistent data** can cause confusion, mistakes, and incorrect results.\n",
    "- Fixing it involves:\n",
    "  - **Correcting typos**.\n",
    "  - **Standardizing naming conventions**.\n",
    "  - **Consistent formatting** (like dates, phone numbers, etc.).\n",
    "  - **Removing extra spaces**.\n",
    "- **Consistent data** is cleaner and easier to work with, ensuring better analysis and more accurate results.\n",
    "\n",
    "By fixing inconsistent data, you help ensure that your data is **accurate** and **uniform**, which ultimately leads to **better decision-making** and more **reliable models**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
