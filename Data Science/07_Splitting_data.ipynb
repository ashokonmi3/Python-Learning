{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting for Machine Learning\n",
    "\n",
    "Data splitting is a crucial step in building machine learning models. It helps in evaluating the model's performance and preventing overfitting. Here's an overview and explanation of the different data splits used in training machine learning models.\n",
    "\n",
    "## 1. Training Set:\n",
    "   - **Purpose**: The training set is used to teach the model how to make predictions. It contains labeled examples (inputs with known outputs), which the model learns from.\n",
    "   - **Size**: Typically, around 70-80% of the total dataset is used for training.\n",
    "   - **Example**: If you have 1000 data points, you might use 700-800 of those for training.\n",
    "\n",
    "## 2. Validation Set:\n",
    "   - **Purpose**: The validation set is used to fine-tune the model’s hyperparameters (such as learning rate, number of trees in a decision tree model, etc.) and to avoid overfitting.\n",
    "   - **Size**: Around 10-15% of the total dataset.\n",
    "   - **Example**: For a dataset with 1000 data points, 100-150 would be used for validation.\n",
    "\n",
    "## 3. Test Set:\n",
    "   - **Purpose**: The test set is used to evaluate the performance of the final model. It is used after the model is fully trained and tuned. It helps to check how well the model generalizes to unseen data.\n",
    "   - **Size**: Around 10-15% of the total dataset.\n",
    "   - **Example**: Out of 1000 data points, you’d use 100-150 for testing.\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Validation (Optional):\n",
    "Cross-validation is a technique used to make the most out of a limited dataset. It is commonly used when the dataset is small and you want to ensure the model's robustness. One common method is **K-fold Cross-Validation**.\n",
    "\n",
    "### K-fold Cross-Validation:\n",
    "- **Purpose**: This method divides the entire dataset into 'K' equally sized folds. The model is trained on K-1 folds and tested on the remaining fold. This process is repeated K times with a different fold used for testing each time.\n",
    "- **Advantages**:\n",
    "  - It helps in reducing variance and makes sure the model works well on different subsets of data.\n",
    "  - More reliable model evaluation.\n",
    "- **Common Value for K**: Typically, K is set to 5 or 10.\n",
    "\n",
    "**Example of K-fold**:\n",
    "- If you have 1000 data points and set K=5:\n",
    "  - The dataset is split into 5 parts of 200 each.\n",
    "  - The model is trained on 4 folds (800 data points) and tested on the remaining fold (200 data points).\n",
    "  - This process is repeated 5 times, each time using a different fold for testing.\n",
    "\n",
    "---\n",
    "\n",
    "## Why is Data Splitting Important?\n",
    "- **Prevents Overfitting**: By splitting the data, we ensure the model doesn’t memorize the training data (overfitting), making it perform poorly on new, unseen data.\n",
    "- **Evaluates Model Performance**: Data splitting helps us evaluate how well our model generalizes to unseen data.\n",
    "- **Hyperparameter Tuning**: The validation set helps in selecting the best hyperparameters and model architecture, improving the model’s performance.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120\n",
      "Validation set size: 15\n",
      "Test set size: 15\n",
      "Validation Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n",
      "Cross-Validation Accuracy (mean): 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading a sample dataset (Iris dataset)\n",
    "data = load_iris()\n",
    "X = data.data  # Features (independent variables)\n",
    "y = data.target  # Target (dependent variable)\n",
    "\n",
    "# Splitting the dataset into Training (80%), Validation (10%), and Test (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the size of each set\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Create and train a RandomForest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Applying Cross-Validation (5-fold) to assess model performance more robustly\n",
    "cross_val_accuracy = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Cross-Validation Accuracy (mean): {cross_val_accuracy.mean() * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Questions Related to Data Splitting:\n",
    "\n",
    "1. **What is the purpose of splitting a dataset into training, validation, and test sets?**\n",
    "   - **Expected Answer**: The training set is used for learning, the validation set helps tune model parameters, and the test set is used to evaluate the model’s performance.\n",
    "\n",
    "2. **How do you decide the size of the training, validation, and test sets?**\n",
    "   - **Expected Answer**: Typically, 70-80% of the data is used for training, 10-15% for validation, and the remaining 10-15% for testing. The exact split may depend on the size of the dataset and the task at hand.\n",
    "\n",
    "3. **What is K-fold cross-validation, and when would you use it?**\n",
    "   - **Expected Answer**: K-fold cross-validation splits the dataset into K parts. The model is trained K times, each time with a different fold used for testing and the remaining K-1 folds used for training. It is useful when the dataset is small, and we want to ensure the model's performance is stable across different subsets.\n",
    "\n",
    "4. **What is the difference between validation and test sets?**\n",
    "   - **Expected Answer**: The validation set is used during the model training phase to fine-tune hyperparameters, while the test set is used only after training to evaluate the final model’s performance.\n",
    "\n",
    "5. **What could be the consequence of not splitting the data into training and testing sets?**\n",
    "   - **Expected Answer**: The model could overfit the training data, and its performance on unseen data would likely be poor. Without a test set, there’s no way to evaluate how well the model generalizes to new data.\n",
    "\n",
    "6. **When would you prefer not to use cross-validation?**\n",
    "   - **Expected Answer**: If the dataset is very large, running cross-validation might be computationally expensive and unnecessary. In such cases, a simple split into training and test sets may be sufficient.\n",
    "\n",
    "7. **How does cross-validation help in model selection?**\n",
    "   - **Expected Answer**: Cross-validation provides a more robust estimate of model performance by training and testing on different subsets of the data. This helps in selecting the model that performs well across all folds, thus ensuring better generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways:\n",
    "- Splitting data into training, validation, and test sets helps ensure your model is both well-trained and capable of generalizing to new data.\n",
    "- Cross-validation is an optional but effective technique for improving model evaluation, especially when working with smaller datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
