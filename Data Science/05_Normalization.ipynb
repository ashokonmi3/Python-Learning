{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data: Normalization\n",
    "\n",
    "## Introduction to Scaling and Normalization\n",
    "In machine learning, data often comes in various forms, which means the values can range from small to large numbers. Some algorithms, like distance-based algorithms (e.g., K-Nearest Neighbors or Support Vector Machines), are sensitive to the scale of the data. When features (variables) are on different scales, it can impact the model's performance and accuracy. \n",
    "\n",
    "### What is Normalization?\n",
    "Normalization is the process of adjusting the data so that all the features have similar scales. This is often done by rescaling the data between a certain range, typically between 0 and 1. This makes sure that one feature does not dominate the model because of its large numerical range.\n",
    "\n",
    "### Why is Normalization Important?\n",
    "- **Improves Performance:** When features are scaled, it helps machine learning algorithms converge faster.\n",
    "- **Prevents Bias:** Some algorithms may give more weight to features with larger values, skewing results. Normalization ensures that all features are treated equally.\n",
    "\n",
    "Normalization is a way to make sure that all the data we use in a machine learning model is on the **same scale**. This means that we change the data so that every feature (or column of data) has similar values, making it easier for the model to understand and process.\n",
    "\n",
    "### Why do we need Normalization?\n",
    "\n",
    "Imagine you have two types of data: \n",
    "1. **Height of people** in **cm** (ranging from 150 cm to 200 cm).\n",
    "2. **Age of people** in **years** (ranging from 18 to 60 years).\n",
    "\n",
    "In this case, **height** and **age** are on very different scales. One is between 150 and 200, and the other is between 18 and 60. If you put them both in a model without normalizing, the **height** might end up influencing the results more because its range is bigger. \n",
    "\n",
    "Normalization **makes both features (height and age) on the same level**, so they are treated equally by the machine learning model.\n",
    "\n",
    "## A Simple Example\n",
    "\n",
    "Let's say we have the following data:\n",
    "\n",
    "| Person | Height (cm) | Age (years) |\n",
    "|--------|-------------|-------------|\n",
    "| Alice  | 160         | 25          |\n",
    "| Bob    | 170         | 30          |\n",
    "| Charlie| 180         | 35          |\n",
    "\n",
    "- **Height** is between 160 and 180 cm.\n",
    "- **Age** is between 25 and 35 years.\n",
    "\n",
    "Both features (Height and Age) are on different scales. To **normalize** the data, we can scale each feature so that it fits within a range between **0 and 1**. This makes sure both features are treated equally when used in a machine learning model.\n",
    "\n",
    "\n",
    "## Types of Normalization\n",
    "\n",
    "### 1. Min-Max Normalization:\n",
    "This is the most commonly used method where each feature is scaled to a specific range, usually between 0 and 1. The formula is:\n",
    "\n",
    "![My Image](./images/Min-Max-Normalization.jpg)\n",
    "\n",
    "\n",
    "\n",
    "### 2. Z-Score Normalization (Standardization):\n",
    "In this approach, the data is transformed so that it has a mean of 0 and a standard deviation of 1. The formula is:\n",
    "\n",
    "\\[\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(X\\) is the value,\n",
    "- \\(\\mu\\) is the mean of the feature,\n",
    "- \\(\\sigma\\) is the standard deviation of the feature.\n",
    "\n",
    "This method is often used when the data has outliers, as it helps in dealing with large variance in features.\n",
    "\n",
    "## When to Use Normalization:\n",
    "- **Use Min-Max normalization** when your data has a known range, and you want to scale it to a specific range like [0, 1].\n",
    "- **Use Z-score normalization** when your data has varying scales or outliers, and you need to center the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## What Happens During Normalization?\n",
    "\n",
    "Normalization changes the data so that all the values are between **0 and 1**. This is done by using a simple formula:\n",
    "\n",
    "Normalized Value = (Current Value - Min Value) / (Max Value - Min Value)\n",
    "\n",
    "Where:\n",
    "- **Current Value** is the original value you want to normalize.\n",
    "- **Min Value** is the smallest value in the feature.\n",
    "- **Max Value** is the largest value in the feature.\n",
    "\n",
    "### Example: Normalizing the Height and Age\n",
    "\n",
    "For **Height** (between 160 and 180 cm):\n",
    "\n",
    "- **For Alice** (Height = 160 cm):\n",
    "\n",
    "Normalized Height = (160 - 160) / (180 - 160) = 0\n",
    "\n",
    "- **For Bob** (Height = 170 cm):\n",
    "Normalized Height = (170 - 160) / (180 - 160) = 0.5\n",
    "\n",
    "- **For Charlie** (Height = 180 cm):\n",
    "Normalized Height = (180 - 160) / (180 - 160) = 1\n",
    "\n",
    "For **Age** (between 25 and 35 years):\n",
    "\n",
    "- **For Alice** (Age = 25)\n",
    "\n",
    "Normalized Age = (25 - 25) / (35 - 25) = 0\n",
    "\n",
    "### Result:\n",
    "\n",
    "| Person | Normalized Height | Normalized Age |\n",
    "|--------|-------------------|----------------|\n",
    "| Alice  | 0.0               | 0.0            |\n",
    "| Bob    | 0.5               | 0.5            |\n",
    "| Charlie| 1.0               | 1.0            |\n",
    "\n",
    "Now both **Height** and **Age** are between 0 and 1, and the machine learning model will treat them equally.\n",
    "\n",
    "## Code Example: Normalizing Data in Python\n",
    "\n",
    "You can use Python and a special library called `sklearn` to normalize your data automatically. Here's a simple Python code:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Height  Age\n",
      "0     160   25\n",
      "1     170   30\n",
      "2     180   35\n",
      "\n",
      "Normalized Data:\n",
      "   Normalized Height  Normalized Age\n",
      "0                0.0             0.0\n",
      "1                0.5             0.5\n",
      "2                1.0             1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Data: Heights and Ages\n",
    "data = {'Height': [160, 170, 180],\n",
    "        'Age': [25, 30, 35]}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original data\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Creating a Normalizer (MinMaxScaler)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizing the data\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "\n",
    "# Creating a DataFrame with normalized values\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=[\n",
    "                             'Normalized Height', 'Normalized Age'])\n",
    "\n",
    "# Display the normalized data\n",
    "print(\"\\nNormalized Data:\")\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-Score Normalization in Simple Language\n",
    "\n",
    "## What is Z-Score Normalization?\n",
    "\n",
    "**Z-score normalization**, also known as **standardization**, is a way to adjust the data so that it has a mean (average) of **0** and a standard deviation of **1**. This makes the data easier for machine learning models to understand and process, especially when the data varies greatly in scale.\n",
    "\n",
    "## Why Use Z-Score Normalization?\n",
    "\n",
    "Imagine you have two features in your data:\n",
    "\n",
    "1. **Height**: People’s heights in centimeters (e.g., 150 cm, 170 cm, 180 cm)\n",
    "2. **Age**: People’s ages in years (e.g., 20 years, 40 years, 60 years)\n",
    "\n",
    "If you don’t normalize these values, the **Age** feature might seem more important in the model because it has a much wider range (20 to 60 years) compared to **Height** (150 cm to 180 cm). Z-score normalization helps by giving both features equal importance.\n",
    "\n",
    "## How Does It Work?\n",
    "\n",
    "Z-score normalization turns the data into a **standardized score** by considering how far each value is from the **average** (mean) and how **spread out** the values are (standard deviation).\n",
    "\n",
    "### Formula:\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "\n",
    "Where:\n",
    "- **X** is the original value (e.g., someone’s height or age),\n",
    "- **μ (mu)** is the **average** (mean) of all the values,\n",
    "- **σ (sigma)** is the **standard deviation**, which tells us how spread out the values are.\n",
    "\n",
    "The result, **Z**, tells us how far a specific value is from the average, in terms of how many \"standard deviations\" it is away.\n",
    "\n",
    "## Simple Example:\n",
    "\n",
    "Let’s say we have these **Heights**: 150 cm, 160 cm, 170 cm, 180 cm.\n",
    "\n",
    "- The **mean** (average) height is **160 cm**.\n",
    "- The **standard deviation** is **10 cm** (this shows how spread out the values are).\n",
    "\n",
    "Now, let’s normalize a height of **170 cm** using the formula:\n",
    "\n",
    "Z = (170 - 160) / 10 = 10 / 10 = 1\n",
    "\n",
    "\n",
    "This means **170 cm** is **1 standard deviation** above the average.\n",
    "\n",
    "If someone’s height is **150 cm**, the Z-score would be:\n",
    "\n",
    "Z = (150 - 160) / 10 = -10 / 10 = -1\n",
    "\n",
    "\n",
    "This means **150 cm** is **1 standard deviation** below the average.\n",
    "\n",
    "## What Does This Mean?\n",
    "\n",
    "- **Z-scores** help us understand how far or close a value is from the average in a standardized way.\n",
    "- After Z-score normalization, all features (like height, age, weight) will have values centered around **0** and can be compared more easily.\n",
    "- This technique is useful when the data has different units or scales (e.g., height in centimeters and weight in kilograms), making sure that no single feature dominates the model because of its scale.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "Z-score normalization is a way to make data comparable by adjusting it to have a mean of **0** and a standard deviation of **1**. It helps in giving all features the same importance when building machine learning models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Height\n",
      "0     150\n",
      "1     160\n",
      "2     170\n",
      "3     180\n",
      "\n",
      "Normalized Data (Z-score):\n",
      "   Normalized Height\n",
      "0          -1.341641\n",
      "1          -0.447214\n",
      "2           0.447214\n",
      "3           1.341641\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Data: Heights\n",
    "data = {'Height': [150, 160, 170, 180]}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original data\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Creating a Z-score Normalizer (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalizing the data using Z-score normalization\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "\n",
    "# Creating a DataFrame with normalized values\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=['Normalized Height'])\n",
    "\n",
    "# Display the normalized data\n",
    "print(\"\\nNormalized Data (Z-score):\")\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Normalization (L1 Regularization)\n",
    "\n",
    "**L1 Normalization** is a technique used in machine learning to help a model make better predictions by **ignoring irrelevant information**.\n",
    "\n",
    "## What is L1 Normalization?\n",
    "\n",
    "Imagine you're making a decision based on several factors. For example, when deciding what car to buy, you might consider the **color**, **price**, **fuel efficiency**, and **safety features**. Some of these factors might matter more than others.\n",
    "\n",
    "In machine learning, we often have many factors (called **features**). L1 Normalization helps the model decide which factors are **important** and which ones it can **ignore**. It does this by setting the **less important features** to **zero**, so the model focuses on just the important ones.\n",
    "\n",
    "## Why is L1 Normalization Useful?\n",
    "\n",
    "1. **Simplifies the Model**: By ignoring irrelevant features, the model becomes **simpler** and **faster**.\n",
    "2. **Improves Accuracy**: With fewer features to worry about, the model can focus on what really matters, which can lead to **better predictions**.\n",
    "3. **Prevents Overfitting**: Overfitting happens when the model gets too complicated and starts \"memorizing\" data instead of learning from it. L1 helps by keeping things simple.\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "Imagine you're building a model to predict whether someone will buy a product based on **age**, **income**, and **number of social media followers**.\n",
    "\n",
    "- **Without L1 Normalization**: The model might use all three features equally, even though the number of social media followers might not really matter.\n",
    "- **With L1 Normalization**: The model might decide that **\"number of social media followers\"** isn’t important and completely **ignore it** by setting its value to zero. This makes the model **simpler** and **faster**.\n",
    "\n",
    "## How Does L1 Normalization Work?\n",
    "\n",
    "L1 Normalization works by **shrinking** the importance of features that don’t help with predictions. It gives **zero importance** to unimportant features, so they don’t influence the model’s decision-making.\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **L1 Normalization** helps the machine focus only on the important features and **ignores the unimportant ones**.\n",
    "- It makes the model **simpler**, **faster**, and **more accurate**.\n",
    "- It’s especially useful when you have a lot of features and want to find out which ones really matter.\n",
    "\n",
    "L1 Normalization is like cleaning up your decision-making process by throwing out irrelevant details and focusing on what truly matters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "2                     0.672   32  \n",
      "3                     0.167   21  \n",
      "4                     2.288   33  \n",
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.017380  0.428703       0.208558       0.101383  0.000000  0.097327   \n",
      "1     0.004185  0.355721       0.276207       0.121364  0.000000  0.111320   \n",
      "2     0.025726  0.588477       0.205806       0.000000  0.000000  0.074926   \n",
      "3     0.003103  0.276169       0.204799       0.071369  0.291684  0.087195   \n",
      "4     0.000000  0.298873       0.087262       0.076355  0.366502  0.094025   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  Outcome  \n",
      "0                  0.001816  0.144832        1  \n",
      "1                  0.001469  0.129734        0  \n",
      "2                  0.002161  0.102903        1  \n",
      "3                  0.000518  0.065163        0  \n",
      "4                  0.004991  0.071991        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Load the CSV file\n",
    "# Replace with your actual CSV file path\n",
    "path = r'diabetes.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Select the features to normalize (excluding the target variable 'Outcome')\n",
    "features = data.drop(columns=['Outcome'])\n",
    "print(features.head())\n",
    "# Create a Normalizer object for L1 normalization\n",
    "scaler = Normalizer(norm='l1')\n",
    "\n",
    "# Apply L1 normalization\n",
    "normalized_data = scaler.fit_transform(features)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=features.columns)\n",
    "\n",
    "# Add the 'Outcome' column back to the normalized data\n",
    "normalized_df['Outcome'] = data['Outcome']\n",
    "\n",
    "# Print the normalized data\n",
    "print(normalized_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age  Salary  Country Purchased\n",
      "0  0.000611     1.0   France        No\n",
      "1  0.000562     1.0    Spain       Yes\n",
      "2  0.000556     1.0  Germany        No\n",
      "3  0.000623     1.0    Spain        No\n",
      "4  0.000627     1.0  Germany       Yes\n",
      "5  0.000603     1.0   France       Yes\n",
      "6  0.000746     1.0    Spain        No\n",
      "7  0.000608     1.0   France       Yes\n",
      "8  0.000602     1.0  Germany        No\n",
      "9  0.000552     1.0   France       Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_18536\\275496586.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_18536\\275496586.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Sample CSV data\n",
    "data = {\n",
    "    'Country': ['France', 'Spain', 'Germany', 'Spain', 'Germany', 'France', 'Spain', 'France', 'Germany', 'France'],\n",
    "    'Age': [44, 27, 30, 38, 40, 35, None, 48, 50, 37],\n",
    "    'Salary': [72000, 48000, 54000, 61000, None, 58000, 52000, 79000, 83000, 67000],\n",
    "    'Purchased': ['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing values (NaN) with the mean of the respective column\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Extract the features we want to normalize\n",
    "features = df[['Age', 'Salary']]\n",
    "\n",
    "# Initialize the Normalizer for L2 normalization\n",
    "scaler = Normalizer(norm='l2')\n",
    "\n",
    "# Apply L2 normalization\n",
    "normalized_data = scaler.fit_transform(features)\n",
    "\n",
    "# Create a new DataFrame with the normalized data\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=['Age', 'Salary'])\n",
    "\n",
    "# Add the 'Country' and 'Purchased' columns back to the normalized data\n",
    "normalized_df['Country'] = df['Country']\n",
    "normalized_df['Purchased'] = df['Purchased']\n",
    "\n",
    "# Display the normalized data\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country        Age        Salary Purchased  Age_Standardized  \\\n",
      "0   France  44.000000  72000.000000        No          0.758874   \n",
      "1    Spain  27.000000  48000.000000       Yes         -1.711504   \n",
      "2  Germany  30.000000  54000.000000        No         -1.275555   \n",
      "3    Spain  38.000000  61000.000000        No         -0.113024   \n",
      "4  Germany  40.000000  63777.777778       Yes          0.177609   \n",
      "5   France  35.000000  58000.000000       Yes         -0.548973   \n",
      "6    Spain  38.777778  52000.000000        No          0.000000   \n",
      "7   France  48.000000  79000.000000       Yes          1.340140   \n",
      "8  Germany  50.000000  83000.000000        No          1.630773   \n",
      "9   France  37.000000  67000.000000       Yes         -0.258340   \n",
      "\n",
      "   Salary_Standardized  \n",
      "0         7.494733e-01  \n",
      "1        -1.438178e+00  \n",
      "2        -8.912655e-01  \n",
      "3        -2.532004e-01  \n",
      "4         6.632192e-16  \n",
      "5        -5.266569e-01  \n",
      "6        -1.073570e+00  \n",
      "7         1.387538e+00  \n",
      "8         1.752147e+00  \n",
      "9         2.937125e-01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_1376\\868784739.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_1376\\868784739.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Salary'].fillna(data['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"Data.csv\")\n",
    "\n",
    "# Fill missing values with the mean (optional step for simplicity)\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Salary'].fillna(data['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Select the columns to standardize\n",
    "features = data[['Age', 'Salary']]\n",
    "\n",
    "# Apply Standardization\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(features)\n",
    "\n",
    "# Convert back to a DataFrame for better readability\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=[\n",
    "                               'Age_Standardized', 'Salary_Standardized'])\n",
    "\n",
    "# Merge with the original DataFrame\n",
    "result = pd.concat([data, standardized_df], axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (7, 2)\n",
      "Testing Features Shape: (3, 2)\n",
      "Training Target Shape: (7,)\n",
      "Testing Target Shape: (3,)\n",
      "\n",
      "Training Features:\n",
      "     Age        Salary\n",
      "0  44.0  72000.000000\n",
      "7  48.0  79000.000000\n",
      "2  30.0  54000.000000\n",
      "9  37.0  67000.000000\n",
      "4  40.0  63777.777778\n",
      "\n",
      "Testing Features:\n",
      "     Age   Salary\n",
      "8  50.0  83000.0\n",
      "1  27.0  48000.0\n",
      "5  35.0  58000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_1376\\1599827662.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
      "C:\\Users\\91973\\AppData\\Local\\Temp\\ipykernel_1376\\1599827662.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Salary'].fillna(data['Salary'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Data.csv\")\n",
    "\n",
    "# Fill missing values (optional, for simplicity)\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Salary'].fillna(data['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data[['Age', 'Salary']]  # Features (independent variables)\n",
    "y = data['Purchased']        # Target (dependent variable)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Training Features Shape:\", X_train.shape)\n",
    "print(\"Testing Features Shape:\", X_test.shape)\n",
    "print(\"Training Target Shape:\", y_train.shape)\n",
    "print(\"Testing Target Shape:\", y_test.shape)\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nTraining Features:\\n\", X_train.head())\n",
    "print(\"\\nTesting Features:\\n\", X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
